{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = 'DATA_1/Train'\n",
    "validation_data_dir = 'DATA_1/Test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "                                  a\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "model_vgg = Sequential()\n",
    "model_vgg.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "model_vgg.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model_vgg.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model_vgg.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model_vgg.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model_vgg.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model_vgg.add(ZeroPadding2D((1,1)))\n",
    "model_vgg.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model_vgg.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model_vgg.add(Flatten(name=\"flatten\"))\n",
    "model_vgg.add(Dense(4096, activation='relu', name='dense_1'))\n",
    "model_vgg.add(Dropout(0.5))\n",
    "model_vgg.add(Dense(4096, activation='relu', name='dense_2'))\n",
    "model_vgg.add(Dropout(0.5))\n",
    "model_vgg.add(Dense(2, name='dense_3'))\n",
    "model_vgg.add(Activation(\"softmax\",name=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           zeropadding2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv1_1 (Convolution2D)          (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           conv1_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1_2 (Convolution2D)          (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           conv1_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1 (Convolution2D)          (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           conv2_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2 (Convolution2D)          (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           conv2_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1 (Convolution2D)          (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           conv3_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2 (Convolution2D)          (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           conv3_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3 (Convolution2D)          (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           conv3_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1 (Convolution2D)          (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           conv4_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2 (Convolution2D)          (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           conv4_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3 (Convolution2D)          (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           conv4_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1 (Convolution2D)          (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           conv5_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2 (Convolution2D)          (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           conv5_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3 (Convolution2D)          (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           conv5_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2)             8194        dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "softmax (Activation)             (None, 2)             0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naveen/anaconda2/envs/keras_theano/lib/python2.7/site-packages/theano/tensor/basic.py:2146: UserWarning: theano.tensor.round() changed its default from `half_away_from_zero` to `half_to_even` to have the same default as NumPy. Use the Theano flag `warn.round=False` to disable this warning.\n",
      "  \"theano.tensor.round() changed its default from\"\n"
     ]
    }
   ],
   "source": [
    "model_vgg.compile(loss='binary_crossentropy',\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])\n",
    "nb_epoch = 50\n",
    "nb_train_samples = 5312\n",
    "nb_validation_samples = 1332"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainig the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5312/5312 [==============================] - 3910s - loss: 0.6808 - acc: 0.6178 - val_loss: 0.6440 - val_acc: 0.6719\n",
      "Epoch 2/50\n",
      "5312/5312 [==============================] - 3932s - loss: 0.6400 - acc: 0.6583 - val_loss: 0.6793 - val_acc: 0.5113\n",
      "Epoch 3/50\n",
      "5312/5312 [==============================] - 3970s - loss: 0.6719 - acc: 0.5847 - val_loss: 0.6230 - val_acc: 0.7312\n",
      "Epoch 4/50\n",
      "5312/5312 [==============================] - 3962s - loss: 0.6521 - acc: 0.6555 - val_loss: 0.6211 - val_acc: 0.6674\n",
      "Epoch 5/50\n",
      "5312/5312 [==============================] - 4409s - loss: 0.6435 - acc: 0.6455 - val_loss: 0.6316 - val_acc: 0.6764\n",
      "Epoch 6/50\n",
      "5312/5312 [==============================] - 5367s - loss: 0.6062 - acc: 0.6943 - val_loss: 0.3948 - val_acc: 0.8423\n",
      "Epoch 7/50\n",
      "5312/5312 [==============================] - 4021s - loss: 0.5953 - acc: 0.7142 - val_loss: 0.5321 - val_acc: 0.7320\n",
      "Epoch 8/50\n",
      "5312/5312 [==============================] - 4013s - loss: 0.5496 - acc: 0.7449 - val_loss: 0.3143 - val_acc: 0.8709\n",
      "Epoch 9/50\n",
      "5312/5312 [==============================] - 3976s - loss: 0.3945 - acc: 0.8415 - val_loss: 0.2090 - val_acc: 0.9212\n",
      "Epoch 10/50\n",
      "5312/5312 [==============================] - 3972s - loss: 0.3381 - acc: 0.8663 - val_loss: 0.2113 - val_acc: 0.9264\n",
      "Epoch 11/50\n",
      "5312/5312 [==============================] - 3952s - loss: 0.2988 - acc: 0.8820 - val_loss: 0.1992 - val_acc: 0.9279\n",
      "Epoch 12/50\n",
      "5312/5312 [==============================] - 3949s - loss: 0.3917 - acc: 0.8358 - val_loss: 0.1023 - val_acc: 0.9677\n",
      "Epoch 13/50\n",
      "5312/5312 [==============================] - 3952s - loss: 0.3013 - acc: 0.8780 - val_loss: 0.0839 - val_acc: 0.9715\n",
      "Epoch 14/50\n",
      "5312/5312 [==============================] - 3956s - loss: 0.2391 - acc: 0.9038 - val_loss: 0.0896 - val_acc: 0.9700\n",
      "Epoch 15/50\n",
      "5312/5312 [==============================] - 3960s - loss: 0.1751 - acc: 0.9345 - val_loss: 0.0833 - val_acc: 0.9707\n",
      "Epoch 16/50\n",
      "5312/5312 [==============================] - 3975s - loss: 0.2080 - acc: 0.9223 - val_loss: 0.0847 - val_acc: 0.9715\n",
      "Epoch 17/50\n",
      "5312/5312 [==============================] - 3955s - loss: 0.1866 - acc: 0.9271 - val_loss: 0.0600 - val_acc: 0.9797\n",
      "Epoch 18/50\n",
      "5312/5312 [==============================] - 3956s - loss: 0.1952 - acc: 0.9277 - val_loss: 0.0895 - val_acc: 0.9700\n",
      "Epoch 19/50\n",
      "5312/5312 [==============================] - 3964s - loss: 0.1629 - acc: 0.9431 - val_loss: 0.0735 - val_acc: 0.9805\n",
      "Epoch 20/50\n",
      "5312/5312 [==============================] - 3957s - loss: 0.1614 - acc: 0.9405 - val_loss: 0.0772 - val_acc: 0.9745\n",
      "Epoch 21/50\n",
      "5312/5312 [==============================] - 3975s - loss: 0.1454 - acc: 0.9448 - val_loss: 0.0700 - val_acc: 0.9797\n",
      "Epoch 22/50\n",
      "5312/5312 [==============================] - 3979s - loss: 0.1313 - acc: 0.9533 - val_loss: 0.0585 - val_acc: 0.9835\n",
      "Epoch 23/50\n",
      "5312/5312 [==============================] - 3991s - loss: 0.1403 - acc: 0.9492 - val_loss: 0.0572 - val_acc: 0.9805\n",
      "Epoch 24/50\n",
      "5312/5312 [==============================] - 3996s - loss: 0.1219 - acc: 0.9552 - val_loss: 0.0582 - val_acc: 0.9805\n",
      "Epoch 25/50\n",
      "5312/5312 [==============================] - 4005s - loss: 0.1292 - acc: 0.9561 - val_loss: 0.0612 - val_acc: 0.9790\n",
      "Epoch 26/50\n",
      "5312/5312 [==============================] - 4312s - loss: 0.1167 - acc: 0.9578 - val_loss: 0.0527 - val_acc: 0.9790\n",
      "Epoch 27/50\n",
      "5312/5312 [==============================] - 4543s - loss: 0.1084 - acc: 0.9618 - val_loss: 0.0482 - val_acc: 0.9805\n",
      "Epoch 28/50\n",
      "5312/5312 [==============================] - 6613s - loss: 0.1152 - acc: 0.9605 - val_loss: 0.0642 - val_acc: 0.9752\n",
      "Epoch 29/50\n",
      "5312/5312 [==============================] - 6569s - loss: 0.1000 - acc: 0.9639 - val_loss: 0.0573 - val_acc: 0.9820\n",
      "Epoch 30/50\n",
      "5312/5312 [==============================] - 6539s - loss: 0.1044 - acc: 0.9612 - val_loss: 0.0554 - val_acc: 0.9805\n",
      "Epoch 31/50\n",
      "5312/5312 [==============================] - 6578s - loss: 0.1533 - acc: 0.9398 - val_loss: 0.0678 - val_acc: 0.9790\n",
      "Epoch 32/50\n",
      "5312/5312 [==============================] - 6563s - loss: 0.1014 - acc: 0.9655 - val_loss: 0.0401 - val_acc: 0.9872\n",
      "Epoch 33/50\n",
      "5312/5312 [==============================] - 6559s - loss: 0.0951 - acc: 0.9672 - val_loss: 0.0643 - val_acc: 0.9805\n",
      "Epoch 34/50\n",
      "5312/5312 [==============================] - 6597s - loss: 0.1098 - acc: 0.9599 - val_loss: 0.0531 - val_acc: 0.9812\n",
      "Epoch 35/50\n",
      "5312/5312 [==============================] - 6583s - loss: 0.0967 - acc: 0.9657 - val_loss: 0.0507 - val_acc: 0.9805\n",
      "Epoch 36/50\n",
      "5312/5312 [==============================] - 6549s - loss: 0.0918 - acc: 0.9674 - val_loss: 0.0545 - val_acc: 0.9812\n",
      "Epoch 37/50\n",
      "5312/5312 [==============================] - 6616s - loss: 0.0868 - acc: 0.9655 - val_loss: 0.0662 - val_acc: 0.9790\n",
      "Epoch 38/50\n",
      "5312/5312 [==============================] - 6655s - loss: 0.0895 - acc: 0.9695 - val_loss: 0.0595 - val_acc: 0.9835\n",
      "Epoch 39/50\n",
      "5312/5312 [==============================] - 6631s - loss: 0.0839 - acc: 0.9708 - val_loss: 0.0433 - val_acc: 0.9887\n",
      "Epoch 40/50\n",
      "5312/5312 [==============================] - 6651s - loss: 0.0745 - acc: 0.9720 - val_loss: 0.0687 - val_acc: 0.9790\n",
      "Epoch 41/50\n",
      "5312/5312 [==============================] - 6605s - loss: 0.0775 - acc: 0.9742 - val_loss: 0.0462 - val_acc: 0.9842\n",
      "Epoch 42/50\n",
      "5312/5312 [==============================] - 6639s - loss: 0.0897 - acc: 0.9674 - val_loss: 0.0500 - val_acc: 0.9812\n",
      "Epoch 43/50\n",
      "5312/5312 [==============================] - 6629s - loss: 0.0764 - acc: 0.9731 - val_loss: 0.0472 - val_acc: 0.9857\n",
      "Epoch 44/50\n",
      "5312/5312 [==============================] - 6617s - loss: 0.0708 - acc: 0.9767 - val_loss: 0.0451 - val_acc: 0.9812\n",
      "Epoch 45/50\n",
      "5312/5312 [==============================] - 6605s - loss: 0.0669 - acc: 0.9774 - val_loss: 0.0667 - val_acc: 0.9820\n",
      "Epoch 46/50\n",
      "5312/5312 [==============================] - 6549s - loss: 0.0772 - acc: 0.9735 - val_loss: 0.0559 - val_acc: 0.9842\n",
      "Epoch 47/50\n",
      "5312/5312 [==============================] - 6557s - loss: 0.0620 - acc: 0.9802 - val_loss: 0.0489 - val_acc: 0.9842\n",
      "Epoch 48/50\n",
      "5312/5312 [==============================] - 5153s - loss: 0.0649 - acc: 0.9761 - val_loss: 0.0622 - val_acc: 0.9797\n",
      "Epoch 49/50\n",
      "5312/5312 [==============================] - 4012s - loss: 0.0642 - acc: 0.9785 - val_loss: 0.0481 - val_acc: 0.9850\n",
      "Epoch 50/50\n",
      "5312/5312 [==============================] - 4025s - loss: 0.0652 - acc: 0.9755 - val_loss: 0.0719 - val_acc: 0.9775\n"
     ]
    }
   ],
   "source": [
    "model_vgg.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n",
    "model_vgg.save('/home/naveen/final-model.h5', model_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1332 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "model_vgg.load_weights('/home/vysakh/My Files/Mini Project/VGG16/keras-workshop-master/models/vgg16/final-model.h5', by_name=True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'DATA_1/Test',  \n",
    "         target_size=(img_width, img_height),\n",
    "         batch_size=32,\n",
    "         shuffle=False,\n",
    "         class_mode='binary')\n",
    "prob=model_vgg.predict_generator(test_generator,1332)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.99      0.97      0.98       666\n",
      "    class 1       0.97      0.99      0.98       666\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1332\n",
      "\n",
      "[[647  19]\n",
      " [  6 660]]\n",
      "0.981231231231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "y_pred=prob>0.5\n",
    "y_pred = np.argmax(prob, axis=1)\n",
    "y_true=np.array([0]*666+ [1]*666)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_true, y_pred)\n",
    "class_names=['Non-Vehicle','Vehicle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[647  19]\n",
      " [  6 660]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAEmCAYAAAAnRIjxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCwnDrBmZjlxgDUzy8n/B5U4CUi9VDpsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba05c34ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    fig.savefig('plot.png')\n",
    "plot_confusion_matrix(cm, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
